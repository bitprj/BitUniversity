{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/bitprj/DigitalHistory/blob/Narae/Week3-Introduction-to-Open-Data-Importing-Data-and-Basic-Data-Wrangling/assets/icons/bitproject.png?raw=1\" width=\"200\" align=\"left\"> \n",
    "<img src=\"https://github.com/bitprj/DigitalHistory/blob/Narae/Week3-Introduction-to-Open-Data-Importing-Data-and-Basic-Data-Wrangling/assets/icons/data-science.jpg?raw=1\" width=\"300\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Advanced Data Wrangling with Pandas</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yl__4vuWJQk8"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- Series\n",
    "    - Creating a Series\n",
    "    - Sorting a Series\n",
    "        - **1.0 - Now Try This**\n",
    "    - Accessing an element in a Series\n",
    "        - **2.0 - Now Try This**\n",
    "        - **3.0 - Now Try This**\n",
    "    - Binary Operations\n",
    "        - **4.0 - Now Try This**\n",
    "\n",
    "- Advanced Dataframe\n",
    "    - Creaing new columns\n",
    "    - Replacing NaN values\n",
    "    - Sorting the dataset\n",
    "    - Selecting subset of data\n",
    "        - **5.0 - Now Try This**\n",
    "    - Dropping entities\n",
    "    - Unique values in columns\n",
    "    - Joining dataset\n",
    "        - Merge\n",
    "        - Join\n",
    "\n",
    "- Practical Exercise: Flight Delay data\n",
    "    - Join dataset\n",
    "    - Groupby\n",
    "    - Filtering based on condition\n",
    "    - **6.0 - Now Try This**\n",
    "    - **7.0 - Now Try This**\n",
    "    - **8.0 - Now Try This**\n",
    "    - **9.0 - Now Try This**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1X9xt1J4K2eD"
   },
   "source": [
    "## Dataframe vs. Series\n",
    "There are two main data structures you need to get comfortable with: **Dataframe** and **Series** (Remember: we covered the basics of DataFrame in Week 3.)\n",
    "\n",
    "To refresh your memory, **DataFrame** is a tabular, column-oriented data structure with both row and column labels. \n",
    "\n",
    "**Series** is 1-dimensional labelled array and it can hold data of any type (integer, string, float, python objects, etc.). Its labels are called indices. You can think of a Series as a ordered dictionary, as it is a mapping of index values to data values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6UlYJSdMkEb"
   },
   "source": [
    "## Series\n",
    "\n",
    "- Creating a Series\n",
    "- Sorting a Series\n",
    "- Accessing an element in a Series\n",
    "- Binary Operations (add, sum, mul, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QYD9FNvNvCy"
   },
   "source": [
    "### Creating a Series\n",
    "\n",
    "A series can be created from \n",
    "1. scalar\n",
    "2. list (array) \n",
    "2. dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX8LOIj-Mx-s"
   },
   "source": [
    "First and foremost, let's import Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PwCmTIwMgvQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6SM5MwCnjJx"
   },
   "source": [
    "#### 1. Series from a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ao8D97SxnmbA"
   },
   "outputs": [],
   "source": [
    "pd.Series(5, index =[0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuTD87cQM7Ic"
   },
   "source": [
    "#### 2-1. Series from a list. \n",
    "\n",
    "By default, index starts at 0 and ends at len(array)-1. \n",
    "\n",
    "In this example, as we didn't specify the index, the first index is 0 and the last index is 4, which is len(array)-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "X5wt-CqFM_8I",
    "outputId": "2722f931-7e41-4e63-c05b-b84cae398e02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.array(['a','b','c','d'])\n",
    "pd.Series(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA3N7-qyNaVM"
   },
   "source": [
    "#### 2-2. Series from a list with index\n",
    "\n",
    "If we want to assign a different index instead of the default ones, we can specify the index as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "2WLaQGvyNZmc",
    "outputId": "4e628e69-a331-4c5d-b57f-99fbd87db48d"
   },
   "outputs": [],
   "source": [
    "array = np.array(['a','b','c','d'])\n",
    "pd.Series(array,index=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4Zr_-rGZpVp"
   },
   "source": [
    "Using the examples below, we can note that Series is NOT ordered by value or index.\n",
    "\n",
    "Instead, Series is ordered in the specified order of indices: 105 --> 103 --> 102 --> 109 --> 104 --> 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "fksXDh47Yjr-",
    "outputId": "029a2b6b-bac8-4f95-d10c-7d7fc0d3fb72"
   },
   "outputs": [],
   "source": [
    "names = np.array(['Daisy', 'Matt', 'Kelly', 'Mike', 'Ashley', 'Kyle'])\n",
    "pd.Series(names, index=[105,103,102,109,104,110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enB_T7hRaY2v"
   },
   "source": [
    "Then, the question is \"Are the indices unique?\"\n",
    "Let's check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Hl52EALyajA9",
    "outputId": "a902b3f1-dbb4-4b9e-d33e-21adb41f24a9"
   },
   "outputs": [],
   "source": [
    "names = np.array(['Daisy', 'Matt', 'Kelly', 'Mike', 'Ashley', 'Kyle'])\n",
    "pd.Series(names, index=[100,100,102,102,103,110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hf0xKPN4aqKO"
   },
   "source": [
    "The indices don't have to be unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eldUp__3a39a"
   },
   "source": [
    "Can we use non-numerical indices?\n",
    "Let's check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "r0OsTILZavIU",
    "outputId": "16dbb9c2-4d5d-4b3e-b15b-2be6e0f8c7a2"
   },
   "outputs": [],
   "source": [
    "names = np.array(['Daisy', 'Matt', 'Kelly', 'Mike'])\n",
    "cities=[\"Atlanta\", \"San Francisco\", \"New York\", \"Seattle\"]\n",
    "\n",
    "pd.Series(names, index=cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grAsKkbMbCz6"
   },
   "source": [
    "We found out that the indices don't have to numbers; indices could be of any types! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "adBBZeBWbJqP",
    "outputId": "62b188dd-820e-4c78-a19a-95cf6448ea1c"
   },
   "outputs": [],
   "source": [
    "names = np.array(['Daisy', 'Matt', 'Kelly', 'Mike'])\n",
    "pd.Series(names, index=[0.79, [0.8, 1.4], 13, \"Hello\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRAJ7s4MMQls"
   },
   "source": [
    "We used float, list, integer, and string as indices and it worked!\n",
    "\n",
    "This example is to demonstrate that you can use any types as indices; in the real world, it's more common to keep the datatype consistent for indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Wxi8Jy6OMW3"
   },
   "source": [
    "#### 3. Series from a dict\n",
    "We can create a Series from a **dict**! Let's see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "zmOi4mPMOXVn",
    "outputId": "a4c1440d-49c9-4be2-a618-5da8d22d3daf"
   },
   "outputs": [],
   "source": [
    "# aDict stores how many fruits we have.\n",
    "aDict = {'Apple':3, 'Banana':5, 'Cherry': 2, 'Mango': 13, 'Peach': 10}\n",
    "pd.Series(aDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtIiqIC1FXd6"
   },
   "source": [
    "When we are passing a dict, the order in the dict is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jd2PNDmkFszH",
    "outputId": "ac176e6e-cdb3-4a22-cd35-296acf51cca2"
   },
   "outputs": [],
   "source": [
    "aDict = {'Mango': 13, 'Banana':5, 'Cherry':2, 'Apple': 3, 'Peach': 10}\n",
    "pd.Series(aDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiHLLOgacg0Q"
   },
   "source": [
    "If we want to know the datatype of Series, we can call dtype function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "llyeLKz7ca8W",
    "outputId": "213a29eb-fc92-4ef9-d502-7f46d674f310"
   },
   "outputs": [],
   "source": [
    "aDict = {'Mango': 13, 'Banana':5, 'Cherry':2, 'Apple': 3, 'Peach': 10}\n",
    "pd.Series(aDict).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_YVm1C9cq9I"
   },
   "source": [
    "Now, let's change the value for \"Mango.\" The value is changed to 13.45 and see what dtype returns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pWcf03jccoUh",
    "outputId": "5c727bb1-df24-4c68-d7e5-f3f3e2dea5db"
   },
   "outputs": [],
   "source": [
    "aDict = {'Mango': 13.45, 'Banana':5, 'Cherry':2, 'Apple': 3, 'Peach': 10}\n",
    "pd.Series(aDict).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82Mus9Lgc8yA"
   },
   "source": [
    "If we want to print out indices only, we can check ```index``` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rmyIfv1jc3fB",
    "outputId": "dbfb5b93-f426-4089-9805-13d88b44e5de"
   },
   "outputs": [],
   "source": [
    "aDict = {'Mango': 13.45, 'Banana':5, 'Cherry':2, 'Apple': 3, 'Peach': 10}\n",
    "pd.Series(aDict).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the values only from a Series. Similarly, we can call ```values``` property from a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(aDict).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_A54Pi5kX6G"
   },
   "source": [
    "### Sorting a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Nf4i2n3G2eU"
   },
   "source": [
    "If we want to sort the Series in the order of \"index\", we can use the ```sort_index()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "UtfyBj5dGxzh",
    "outputId": "9121f6e4-6f59-4205-8c28-bd2d07d2b54a"
   },
   "outputs": [],
   "source": [
    "s = pd.Series(aDict)\n",
    "s.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10CStP_aO6xP"
   },
   "source": [
    "Similarly, if we want to sort the series based on the value, we can use a built-in function sort_values. By default, it will sort the elements in an ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "M6yuEei4OmpK",
    "outputId": "cffd387c-e0ea-402f-9ef7-11ba4e21f007"
   },
   "outputs": [],
   "source": [
    "s = pd.Series(aDict)\n",
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvI4f3ITP3Bc"
   },
   "source": [
    "Let's sort the series in a descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "mv_d1kiTO5vZ",
    "outputId": "d8d8c402-d0d2-4678-852e-093f1697ac15"
   },
   "outputs": [],
   "source": [
    "s.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RItg7im2dJhY"
   },
   "source": [
    "### 1.0 - Now Try This\n",
    "Sort the series by index in a descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tj7D1cz6POtl"
   },
   "source": [
    "### Accessing an element in a Series\n",
    "\n",
    "We can access elements in a Series in the following ways:\n",
    "- by index number\n",
    "- by index label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-wAc-uWR9Hp"
   },
   "outputs": [],
   "source": [
    "array = np.array(['a','b','c','d','e','f','g','h'])\n",
    "s = pd.Series(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaWWGQAGptvL"
   },
   "source": [
    "#### 1. By index number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qpt2sMYhRiTY"
   },
   "source": [
    "We can access the first element by index number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "id": "UCXBaQoQPWnq",
    "outputId": "b6f60de8-9435-4fc8-fc78-ceb93e6ce917"
   },
   "outputs": [],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "id": "Cf64v-7DSViQ",
    "outputId": "0c925119-0002-472b-864f-03bf47ef202c"
   },
   "outputs": [],
   "source": [
    "s[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XMY-qqdmSJo8"
   },
   "source": [
    "We can access the first 3 elements with index operation [:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "e9ipGYg3R4P7",
    "outputId": "cedbd2b3-27d7-4904-9fa7-009fc02e83e2"
   },
   "outputs": [],
   "source": [
    "s[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-bKEGiCpMyx"
   },
   "source": [
    "### 2.0 - Now Try This\n",
    "\n",
    "Access the items in the index of 3-5 (inclusive) using index operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dk4jHp6pzJL"
   },
   "source": [
    "#### By Index Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWDXjvfPS5uQ"
   },
   "source": [
    "\n",
    "We can retrieve a single element using index label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6HRnMdYASH3y",
    "outputId": "71a8191d-49a5-4bfa-8b00-95e2334e0f28"
   },
   "outputs": [],
   "source": [
    "aDict = {'Apple':3, 'Banana':5, 'Cherry': 2, 'Peach': 10}\n",
    "s = pd.Series(aDict)\n",
    "s['Apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NjMMQTHES3CL",
    "outputId": "6a21af8e-cd2a-43cb-be71-06f8a84a272b"
   },
   "outputs": [],
   "source": [
    "s['Peach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dz2IesgGp5a7"
   },
   "source": [
    "### 3.0 - Now Try This\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BW1mziJRTEPn",
    "outputId": "3345a8c5-a8a6-4f6d-ec53-9b7a27dd6364"
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTcTEUUzqDx5"
   },
   "source": [
    "Retrieve an element that corresponds to index 'd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cfbdclds1OSj"
   },
   "source": [
    "### Binary Operations of Series\n",
    "- Add\n",
    "- Sub\n",
    "- Mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFcxfIA91bBj"
   },
   "source": [
    "Here, we have created two Series with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2qRhcz51NfD"
   },
   "outputs": [],
   "source": [
    "# creating a first series\n",
    "s1 = pd.Series([1,5,6,2])\n",
    " \n",
    "# creating a second series\n",
    "s2 = pd.Series([4,1,3,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNXSZot2NkVk"
   },
   "source": [
    "Let's add the two Series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "JpC94kgxNbqd",
    "outputId": "d96cecff-b22b-473b-bede-bebaa62b664b"
   },
   "outputs": [],
   "source": [
    "# answer = s1 + s2\n",
    "answer = s1.add(s2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "td9U_MhY2Lnv"
   },
   "source": [
    "We can also subtract a Series from another Series using sub() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Odw0eFWy2A85",
    "outputId": "447d42e0-d558-418a-a7f3-16976915f9f1"
   },
   "outputs": [],
   "source": [
    "# answer = s1 - s2\n",
    "answer = s1.sub(s2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "i_HM2J9U3ozL",
    "outputId": "765411d9-de0d-4807-ae44-baa2dce203e6"
   },
   "outputs": [],
   "source": [
    "answer = s1.mul(s2)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSpiQb6A29Ag"
   },
   "source": [
    "Using a simpler approach, we can use mathematical notation and it will result in the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "R0BlOzUn3g3u",
    "outputId": "12301b73-596a-48b1-8c72-9140c63acb71"
   },
   "outputs": [],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "JGfGW06a23oM",
    "outputId": "4a428b55-2f7f-4bd6-c0b9-cd06bc4da165"
   },
   "outputs": [],
   "source": [
    "s1 - s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-YR673G22U4X",
    "outputId": "97600d81-faf9-47a2-c530-698b04d8ebaa"
   },
   "outputs": [],
   "source": [
    "s1 * s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJle2PlleXCC"
   },
   "source": [
    "Now, let's create two Series with indices. Note that the order of index is different in two Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s296gpaueBzP"
   },
   "outputs": [],
   "source": [
    "# creating a first series\n",
    "s1 = pd.Series([1,5,6,2], index=['b','c','d','a'])\n",
    " \n",
    "# creating a second series\n",
    "s2 = pd.Series([4,1,3,5], index=['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "f3YngIopeLM2",
    "outputId": "375b0fcb-159c-41e3-88c7-0efc69d20431"
   },
   "outputs": [],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_P6XPZ0KeiAa"
   },
   "source": [
    "s['a'] = 6 was obtained by s1['a'] + s2['a'] and all the other values are calculated in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AJExdsoqNkk"
   },
   "source": [
    "### 4.0 - Now Try This\n",
    "\n",
    "Write down what this code will return on a piece of paper.\n",
    "Compare your answer with the output of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLj-gx-NqYpt"
   },
   "outputs": [],
   "source": [
    "s1 * s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJNR47rL43Zr"
   },
   "source": [
    "## Advanced Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jl3rMWUf6zF0"
   },
   "source": [
    "Now, let's move onto some more advanced ways to use Dataframe. To demontrate this, we'll be using a dataframe on people's income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lj3GrMli4xtz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {'First Name': ['Jennifer', 'Chris', 'John', 'Annie', 'Chloe', 'Jeremy', 'Allison', 'Hannah'], \n",
    "        'Last Name': ['Brown', 'Smith', 'Williams', 'Wong', 'Anderson', 'Scott', 'Kim', 'Mills'], \n",
    "        'Age': [16, 32, 21, 35, 27, 42, 28, 23],\n",
    "        'Hourly Wage': [8,14,60,44,80,54,32,16],\n",
    "        'Hours per week': [20,28,40,40,32,40,40,20],\n",
    "        'Years of experience': [0,2,np.nan,9,np.nan,4,5,np.nan]\n",
    "        } \n",
    "\n",
    "emp = pd.DataFrame(data)\n",
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zl6-3HOnDUxM"
   },
   "source": [
    "### Creating new columns\n",
    "\n",
    "#### String Manipulation\n",
    "\n",
    "We want to have a column displaying the full names of the people in the dataset. To do this, we can combine First Name and Last Name and create a new column called \"Full Name.\"\n",
    "\n",
    "The ```' '``` in the middle is adding a space between the first name and last name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4yC0jbKyBMsS",
    "outputId": "066333c1-4ed3-496d-bdce-de8a999d9bb9"
   },
   "outputs": [],
   "source": [
    "# string manipulation\n",
    "emp['Full Name'] = emp['First Name'] + ' ' + emp['Last Name']\n",
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_Iwt_P6fHqc"
   },
   "source": [
    "#### Numerical column\n",
    "\n",
    "Let's calculate weekly salary for each person and add a column called ```Weekly Salary```. We need to do some simple math to get the weekly salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_d67Iv2Se8WU",
    "outputId": "36c70e94-c510-404f-cb0f-b7c9ac4b9b86"
   },
   "outputs": [],
   "source": [
    "# multiplication of two numerical columns\n",
    "emp['Weekly Salary'] = emp['Hourly Wage'] * emp['Hours per week']\n",
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sVeQuAODYPT"
   },
   "source": [
    "Now, we've added two columns \"Full Name\" and \"Weekly Salary.\"\n",
    "\n",
    "#### List Comprehension\n",
    "\n",
    "Let's create a new column called ```High Income``` based on the ```Weekly Salary```. We will use a list comprehension for this (you can refer to Week 2 materials if you can't recall list comprehension.)\n",
    "\n",
    "```High Income``` will be ```True``` if ```Weekly Salary``` is > 2000, otherwise False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "g3doGL0WBUBA",
    "outputId": "1b5fb8ef-220b-419e-db22-24ce38592d2a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list comprehension\n",
    "emp['High Income'] = [True if x > 2000 else False for x in emp['Weekly Salary']]\n",
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of ```NaN``` values (missing values) in ```Years of experience```.\n",
    "\n",
    "Let's fill in the missing values with 0's using ```fillna(0)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp['Years of experience'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to replace all missing values in the dataset, we can call ```fillna(0)``` on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmD7OwLghrOl"
   },
   "source": [
    "### Sorting the dataset\n",
    "\n",
    "Let's sort the data by 'Weekly Salary'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KaBiarDihijf",
    "outputId": "030dd407-7760-4031-ab38-5fbb940f5a1e"
   },
   "outputs": [],
   "source": [
    "emp.sort_values(by='Weekly Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjwwN40_NNE7"
   },
   "source": [
    "Now, all of the high income workers are located in the bottom of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yylmga3XDdEC"
   },
   "source": [
    "### Selecting subset of data based on condition\n",
    "\n",
    "Let's review how we can select subset of data based on criteria.\n",
    "\n",
    "Selecting rows where 'High Income' is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "YTvKOQLnDCxc",
    "outputId": "bfb2ba13-cce6-47bd-e39d-4be2fcde2f8d"
   },
   "outputs": [],
   "source": [
    "emp[emp['High Income'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05x_BcYbiXE7"
   },
   "source": [
    "### 5.0 - Now Try This\n",
    "\n",
    "Let's find people who are younger than 30 years old AND have high income.\n",
    "\n",
    "(Hint: Make sure to use ```()``` on each condition.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUK8ezg5DjbQ"
   },
   "source": [
    "### Dropping rows\n",
    "\n",
    "There are two ways of dropping rows.\n",
    "\n",
    "1. ```df.drop(index #)```\n",
    "2. ```df.drop(df[<some boolean condition>].index)```: \n",
    "\n",
    "The first line is used when we know exactly what rows we want to drop from the dataframe.\n",
    "With the second line, we can drop rows that do not meet certain criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop rows where 'High Income' is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "WgV-dhN5CpYt",
    "outputId": "7bb6f561-0aba-4e2f-d64b-0792e7bc435e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emp.drop(emp[emp['High Income'] == False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cv86yEkODqPa"
   },
   "source": [
    "Even though we dropped the columns where High Income == False, emp remains unchanged.\n",
    "\n",
    "This is because we didn't update emp!\n",
    "\n",
    "We can update the dataframe once we drop the rows by setting ```inplace=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbmnWKy1PCRc"
   },
   "outputs": [],
   "source": [
    "emp.drop(emp[emp['High Income'] == False].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go! emp has been updated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wc0vZktaD0f2"
   },
   "source": [
    "### Company Dataframe\n",
    "\n",
    "Here, we have the dataset with the company name each person in ```emp``` works for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0yelL2KEN9C"
   },
   "outputs": [],
   "source": [
    "data = {'First Name': ['Jennifer', 'Chris', 'John', 'Annie', 'Chloe', 'Jeremy', 'Allison', 'Hannah'], \n",
    "        'Last Name': ['Brown', 'Smith', 'Williams', 'Wong', 'Anderson', 'Scott', 'Kim', 'Mills'], \n",
    "        'Company': ['Home Depot', 'Bit Project', 'Microsoft', 'Bit Project', 'Disney', 'Adidas', 'Home Depot', np.nan]\n",
    "        } \n",
    "\n",
    "companies = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "h95qFZpcQpp6",
    "outputId": "5cb9c274-692f-4b7b-979e-c7303d249a76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Home Depot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Smith</td>\n",
       "      <td>Bit Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>John</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Annie</td>\n",
       "      <td>Wong</td>\n",
       "      <td>Bit Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>Disney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>Scott</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Allison</td>\n",
       "      <td>Kim</td>\n",
       "      <td>Home Depot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>Mills</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name Last Name      Company\n",
       "0   Jennifer     Brown   Home Depot\n",
       "1      Chris     Smith  Bit Project\n",
       "2       John  Williams    Microsoft\n",
       "3      Annie      Wong  Bit Project\n",
       "4      Chloe  Anderson       Disney\n",
       "5     Jeremy     Scott       Adidas\n",
       "6    Allison       Kim   Home Depot\n",
       "7     Hannah     Mills          NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in NaN values\n",
    "\n",
    "In the dataframe, Hannah's company is ```NaN```. Let's replace it with a string \"UNKNOWN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies['Company'].fillna('UNKNOWN', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values in a column\n",
    "\n",
    "Let's find out the unique company names in the company dataframe.\n",
    "\n",
    "```df[[column_name]].drop_duplicates()```\n",
    "\n",
    "This code will literally drop duplicates in the ```column_name```!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Home Depot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bit Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Disney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company\n",
       "0   Home Depot\n",
       "1  Bit Project\n",
       "2    Microsoft\n",
       "4       Disney\n",
       "5       Adidas\n",
       "7      UNKNOWN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies[[\"Company\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count unique values\n",
    "\n",
    "With ```groupby()``` and ```size()``` functions, we can count the occurrences of a unique value in the ```groupby``` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company\n",
       "Adidas         1\n",
       "Bit Project    2\n",
       "Disney         1\n",
       "Home Depot     2\n",
       "Microsoft      1\n",
       "UNKNOWN        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies.groupby(['Company']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above groups by ```Company``` and return the number of times each company appears in the ```Company``` column.\n",
    "\n",
    "If we want to sort by the size or count, we can use ```sort_values```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company\n",
       "Adidas         1\n",
       "Disney         1\n",
       "Microsoft      1\n",
       "UNKNOWN        1\n",
       "Bit Project    2\n",
       "Home Depot     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies.groupby(['Company']).size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The number of unique values\n",
    "\n",
    "To find out the number of unique values in a column, we can use ```nunique()```.\n",
    "\n",
    "```nunique()``` can be interpreted as **n**umber of **unique** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies[\"Company\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three functions will be very helpful when working with a large, complicated dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Dataset\n",
    "\n",
    "Let's join the two tables ```emp``` and ```companies``` to find out which companies those people work for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pr6JBdx0RYv0"
   },
   "source": [
    "### 1. Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters we can use when we merge two dataframes.\n",
    "\n",
    "```DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes='_x', '_y', copy=True, indicator=False, validate=None)```\n",
    "\n",
    "- how: {‘inner’, ‘left’, ‘right’, ‘outer’}, default ‘inner’\n",
    "- on: Column or index level names to join on. These must be found in both DataFrames.\n",
    "- left_on: Column or index level names to join on in the left DataFrame.\n",
    "- right_on: Column or index level names to join on in the right DataFrame.\n",
    "- left_index: Use the index from the left DataFrame as the join key.\n",
    "- right_index: Use the index from the right DataFrame as the join key\n",
    "- suffixes: A length-2 sequence where each element is optionally a string indicating the suffix to add to overlapping column names in left and right respectively. \n",
    "\n",
    "We will cover the most fundamental and commonly used ones here. Feel free to check for more details at https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - How\n",
    "\n",
    "```how``` indicates a type of ```join``` and there are 4: ```inner```, ```left```, ```right```, and ```outer```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![inner_join.png](assets/inner_join.png)\n",
    "\n",
    "```inner join``` will take in the common items / columns between the two dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![left_join.png](assets/left_join.png)\n",
    "\n",
    "```left join``` will include everything from left dataframe and add a column from right dataframe where there's a match in the right dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![right_join.png](assets/right_join.png)\n",
    "\n",
    "Similar to ```left join```, ```right join``` will include everything from right dataframe and add a column from left dataframe where there's a match in the left dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![full_join.png](assets/full_join.png)\n",
    "\n",
    "```full join``` will include everything from left and right dataframe even if there's no common item between the two dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding different types of ```join```s are very important as this will help us to determine which type of ```join``` we will perform on a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - How Example:\n",
    "\n",
    "We can merge ```emp``` that has weekly salary information and ```companies``` that has the name of the company each person works for.\n",
    "\n",
    "The code below will return a dataframe of two merged objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(emp, companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, it worked! \n",
    "\n",
    "We dropped the rows from ```emp``` where employee's weekly salary is less than $2000, so the updated ```emp``` has 3 entities.\n",
    "\n",
    "By default, ```merge``` performs ```inner join``` and that's why it's showing less number of rows than ```companies``` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try ```right_join``` and see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(emp, companies, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our right dataframe is ```companies``` with 8 entities, it shows all of the 8 employees in ```companies``` dataframe.\n",
    "\n",
    "But, as we've dropped the rows that do not meet our salary expectation in ```emp```, the result of ```right_join``` is missing ```Age```, ```Hourly Wage```, ```Hours per week```, etc for some employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - On, left_on, right_on\n",
    "\n",
    "```on```, ```left_on```, and ```right_on``` indicate a column or index level names to join on.\n",
    "\n",
    "- ```on``` is used when the same column name exists in both dataframes.\n",
    "- ```left_on``` and ```right_on``` is used when the column names are different in two dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - On Example\n",
    "\n",
    "Let's join the two dataframes using common column names, ```First Name``` and ```Last Name```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(emp, companies, on=['First Name', 'Last Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset shows three entities, since ```inner join``` was performed by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - left_on, right_on Example\n",
    "\n",
    "It might happen that the two dataframes we want to merge have different column names.\n",
    "In this case, we will have to specify the left column name and the right column name.\n",
    "\n",
    "Let's join the two dataframes using a different column name. \n",
    "\n",
    "- ```emp``` column name: ```Full Name``` \n",
    "- ```companies``` column name: ```Name```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies['Name'] = companies['First Name'] + ' ' + companies['Last Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lEZwlVLNBo8T",
    "outputId": "40d2cb7f-aee4-4e5f-bf07-5a8227b726aa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(emp, companies, left_on='Full Name', right_on='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, by default, ```inner join``` has been applied and the resulting dataframe show 3 entities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result dataset, ```First Name_x``` is from the first table, which is ```emp``` while ```First Name_y``` is from the second table, which is ```companies```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - Suffixes\n",
    "\n",
    "Suffixes indicate the suffix to add to overlapping column names in left and right respectively.\n",
    "\n",
    "In the previous example, by default, suffixes ```_x``` and ```_y``` were added respectively.\n",
    "\n",
    "We can specify suffixes by setting ```suffixes=[]```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge - Suffixes Example\n",
    "\n",
    "Let's add ```_1``` to the first dataframe and ```_2``` to the second dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(emp, companies, left_on='Full Name', right_on='Name', suffixes=['_1', '_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since inner join was performed, only 3 common entities show up and there's actually no need to indicate ```_1``` or ```_2```.\n",
    "\n",
    "Let's try right join and see how dataframe looks different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(emp, companies, how = 'right', left_on='Full Name', right_on='Name', suffixes=['_emp', '_companies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we specified right join, it shows all of the entities from ```companies``` dataframe and matching entities from ```emp``` dataframe.\n",
    "\n",
    "The ```First Name_emp``` and ```Last Name_emp``` show three entities only while ```First Name_companies``` and ```Last Name_companies``` show all entities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters we can use when we merge two dataframes.\n",
    "\n",
    "```DataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)```\n",
    "\n",
    "- other: DataFrame, Series, or list of DataFrame to join\n",
    "- on: Column or index level names to join on the index in other. These must be found in both DataFrames.\n",
    "- how: {‘inner’, ‘left’, ‘right’, ‘outer’}, default ‘inner’\n",
    "- lsuffix: Suffix to use from left frame’s overlapping columns.\n",
    "- rsuffix: Suffix to use from right frame’s overlapping columns.\n",
    "\n",
    "We have covered ```on``` and ```how``` in detail in ```merge```.\n",
    "\n",
    "So, we will try one example of ```join``` using ```lsuffix``` and ```rsuffix```.\n",
    "\n",
    "#### Join - lsuffix and rsuffix\n",
    "\n",
    "This is similar to ```suffixes``` in ```merge```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "WYdob--7RQVe",
    "outputId": "cebccff2-531f-4db7-cc59-ce71075d8b1f"
   },
   "outputs": [],
   "source": [
    "emp.join(companies, lsuffix='_1', rsuffix='_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0U4y6QmP16K"
   },
   "source": [
    "## Practical Exercise - Flight delay data \n",
    "\n",
    "https://www.kaggle.com/divyansh22/flight-delay-prediction\n",
    "\n",
    "Now, we will dive into a more complicated data analysis using Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ps1EtT8PV7Ud"
   },
   "source": [
    "<img src=\"https://github.com/bitprj/DigitalHistory/blob/Narae/Week6-Advanced-Data-Wrangling-using-Pandas/assets/icons/flight.jpg?raw=1\" width=\"300\" align=\"right\"> \n",
    "\n",
    "This dataset is the flight delay prediction for the month of January. \n",
    "\n",
    "This data is collected from the Bureau of Transportation Statistics, Govt. of the USA. This data is open-sourced under U.S. Govt. Works. This dataset contains all the flights in the month of January 2020. There are more than 400,000 flights in the month of January itself throughout the United States. The features were manually chosen to do a primary time series analysis. There are several other features available on their website.\n",
    "\n",
    "This data could well be used to predict the flight delay at the destination airport specifically for the month of January in upcoming years as the data is for January only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/bitprj/DigitalHistory/master/Week6-Advanced-Data-Wrangling-using-Pandas/data/Jan_2020_ontime.csv'\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, the first thing we need to do is get an idea of what data looks like!\n",
    "We can call three functions here:\n",
    "- head()\n",
    "- describe()\n",
    "- info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns to use:\n",
    "- Day_of_week: Day of Week starting from Monday\n",
    "  - Ex: Monday = 1, Sunday = 7\n",
    "- Op_unique_carrier: Unique Carrier Code (DL, WN, AA, 9E, OO, etc.)\n",
    "- Origin: Origin Airport (JFK, ATL, SFO, LAX, etc.)\n",
    "- Dest: Destination Airport (JFK, ATL, SFO, LAX, etc.)\n",
    "- Dep_time: Actual Departure Time (local time: hhmm)\n",
    "  - Ex: 1848 is 18:48 in local time\n",
    "- Dep_del15: Departure Delay Indicator, 15 Minutes or More (1=Yes, 0=No)\n",
    "- Arr_time: Actual Arrival Time (local time: hhmm)\n",
    "- Arr_del15: Arrival Delay Indicator, 15 Minutes or More (1=Yes, 0=No)\n",
    "- Cancelled: Cancelled Flight Indicator (1=Yes, 0=No)\n",
    "- Diverted: Diverted Flight Indicator (1=Yes, 0=No)\n",
    "- Distance: Distance between airports (miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to select the columns to use using ```[]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = df[[\"DAY_OF_WEEK\", \"OP_UNIQUE_CARRIER\", \"ORIGIN\", \"DEST\", \"DEP_TIME\", \"DEP_DEL15\", \"ARR_TIME\", \"ARR_DEL15\", \"CANCELLED\", \"DIVERTED\", \"DISTANCE\"]]\n",
    "flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 - Now Try This\n",
    "\n",
    "Let's retrieve unique airline codes (```OP_UNIQUE_CARRIER```) from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: We know DL (Delta Air Lines), AA (American Airlines) and a few more major airlines. But, do we know all of the unique carrier codes?**\n",
    "\n",
    "**A: No, we don't! Let's add airline names from another dataset!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yViNs4jEJ1R"
   },
   "source": [
    "### Join datasets\n",
    "- ```flight``` dataframe has ```OP_UNIQUE_CARRIER```, but it is missing airline names.\n",
    "- ```airline_names.xlsx``` has airline codes as well as airline names.\n",
    "\n",
    "Let's join ```flight``` dataframe with ```airline_names.xlsx``` to get airline names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieQhohRGP1mz"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/bitprj/DigitalHistory/master/Week6-Advanced-Data-Wrangling-using-Pandas/data/airline_names.xlsx'\n",
    "airline = pd.read_excel(url)\n",
    "airline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 - Now Try This\n",
    "\n",
    "- Use ```merge``` function to join ```airline``` dataframe to ```flight``` dataframe.\n",
    "- Name the resulting dataframe as ```flight_airline```.\n",
    "- Print ```flight_airline``` and make sure that this dataframe has airline codes AND airline names!\n",
    "\n",
    "(Hint: what are the common column names between two dataframes? Are the column names same?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ```flight_airline``` dataframe has all of the delay, cancellation info as well as airline codes and names!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "- Which airlines experience most delays? (# delays by airline)\n",
    "- Which day of the week experiences most delays? (# delays by the day of a week)\n",
    "- What origins experience most delays? (# delays by origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which airlines experience most delays?\n",
    "\n",
    "This question can be reworded as \"# of delays by airline\"\n",
    "\n",
    "We can use ```groupby``` function to get the number of delays by each airline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_airline.groupby(['carrier','carrier_name'])['DEP_DEL15'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the threshold is 10,000 delays in January, it seems that WN, AA, OO are top three airlines that experience most delays.\n",
    "But often times, passengers would care more about **arrival on time** and that's what airline industries focus more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXzMGcoqEX0_"
   },
   "source": [
    "### 8.0 - Now Try This\n",
    "\n",
    "Calculate sum of ARR_DEL15 using the groupby function and sort the dataset in a descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the same threshold of 10,000 delays, AA, OO, OH, and WN are airlines that experience most delays in regards to **arrival**.\n",
    "\n",
    "We've found the top airlines with most delays but this result does not take into account \"Total number of flights.\"\n",
    "\n",
    "So, it will be more accurate if we can find the percentage of delayed flights for each airline.\n",
    "\n",
    "```delayed flight % = (delayed flights) / (total flights)```\n",
    "\n",
    "Let's calculate **delayed flight %**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code returns the total number of flights\n",
    "flight_airline.groupby(['carrier','carrier_name'])['ARR_DEL15'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this formula, ```delayed flight % = (delayed flights) / (total flights)```\n",
    "\n",
    "we will divide the number of delayed flights by total flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code returns the percentage of delayed flights of each airline.\n",
    "flight_airline.groupby(['carrier','carrier_name'])['ARR_DEL15'].sum() / flight_airline.groupby(['carrier','carrier_name'])['ARR_DEL15'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to see the top airlines with highest delay percentages, let's sort the result in a descending order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_values(ascending = False) has been added\n",
    "(flight_airline.groupby(['carrier','carrier_name'])['ARR_DEL15'].sum() / flight_airline.groupby(['carrier','carrier_name'])['ARR_DEL15'].count()).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tada, we've come up with a completely different result!\n",
    "\n",
    "OH, AS, G4 airlines have highest delay percentages while 9E, DL, HA, WN have reletively low delay percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### agg()\n",
    "\n",
    "The code above is correct but it's very lengthy because we calculate ```sum()``` and ```count()``` separately.\n",
    "\n",
    "We will learn a shortcut to calculate multiple aggregate functions using ```agg()``` argument.\n",
    "\n",
    "Everything remains same, except that we replace ```sum()``` or ```count()``` with ```agg(['sum','count'])```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = flight_airline.groupby(['carrier','carrier_name'])['ARR_DEL15'].agg(['sum','count'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ```new_df``` has columns: ```carrier```, ```carrier_name```, ```sum```, and ```count```.\n",
    "\n",
    "We will create another column called ```delay %``` using sum and count columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['delay %'] = new_df['sum'] / new_df['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tada! We've successfully added a ```delay %``` column! Let's sort the dataframe in a descending order to find out airlines with highest delay %!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.sort_values(by=['delay %'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which day of the week experiences most delays? \n",
    "\n",
    "Let's find out which day of the week experiences most delays!\n",
    "\n",
    "In the data world, this question can be answered if we can find ```# delays by the day of a week```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we can use groupby function, but should we use ```sum```? ```count```? or ```mean```?\n",
    "\n",
    "- ```sum```: The first thing that came to my mind is that we can use ```sum```. But similar to the question above, each day of a week has a different number of flights each day. (Ex: there would be more flights scheduled on weekends.) ```Sum``` is not the most appropriate function to use here.\n",
    "\n",
    "\n",
    "- ```count```: We can count the number of flights and divide ```sum(delayed flights)``` by ```count``` (similar to what we just did)\n",
    "\n",
    "\n",
    "- ```mean```: What if we use ```mean```? We can get the average delay percentage of each day and this is what we are looking for!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_airline.groupby(['DAY_OF_WEEK'])['ARR_DEL15'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that ```mean``` returns same value as ```sum / count```, let's check ```sum / count``` real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_airline.groupby(['DAY_OF_WEEK'])['ARR_DEL15'].sum() / flight_airline.groupby(['DAY_OF_WEEK'])['ARR_DEL15'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! It returns same answer as above!\n",
    "\n",
    "Saturday has the highest delay percentage while Wednesday has the lowest delay percentage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What origins experience most delays? \n",
    "\n",
    "Let's find out what origins experience most delays?\n",
    "\n",
    "Knowing this might help when we book a flight later! :)\n",
    "\n",
    "Since we are dealing with **Origin** airport this time, it's appropriate to use ```DEP_DEL15```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_airline.groupby(['ORIGIN'])['DEP_DEL15'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flight_airline.groupby(['ORIGIN'])['DEP_DEL15'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resulting Series show Origin airports and the corresponding delay %.\n",
    "\n",
    "Since we don't know all of the airport names from the codes, we can join this Series to the dataset that has airport codes and airport names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering based on condition\n",
    "\n",
    "- Which airports have delay percentages of 30% or more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which airports have delay percentages of 30% or more?\n",
    "\n",
    "```airline_delay_causes.csv``` has lots of useful information, but we will extract airport codes and airport names only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/bitprj/DigitalHistory/master/Week6-Advanced-Data-Wrangling-using-Pandas/data/airline_delay_causes.csv'\n",
    "airport_codes = pd.read_csv(url)\n",
    "airport_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airport_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.0 - Now Try This\n",
    "\n",
    "- Using ```drop_duplicates()``` function, find a unique set of airport codes and airport names \n",
    "- Save the dataframe as ```airport_names```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series below is what we have found earlier -- delay % by each origin airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = flight_airline.groupby(['ORIGIN'])['DEP_DEL15'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the result of groupby aggregation to ```DataFrame``` using ```to_frame()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_delays = series.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin_delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a closer look at the question and break it down to smaller subproblems!\n",
    "\n",
    "**Which airports have delay percentages of 30% or more?**\n",
    "1. Find airport codes with a delay percentage greater than 30%.\n",
    "2. Join the resulting dataframe to ```airport_names``` to get airport names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_most_delays = origin_delays[origin_delays['DEP_DEL15'] > 0.3]\n",
    "airports_most_delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(airports_most_delays, airport_names, left_on=\"ORIGIN\", right_on = \"airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've found that ADK, OTH, OGD, PPG, and ASE have highest delay percentages in the US!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop-up Question\n",
    "\n",
    "What if we want to find the delay percentage of a specific airport?\n",
    "\n",
    "Then we can select the origin airport code by using ```df[df[column_name]==\"ABC\"]```\n",
    "\n",
    "Let's check out the delay % of San Francisco airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_delays[origin_delays['ORIGIN'] == 'SFO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above did not work! Why? It's because ```ORIGIN``` is not a column, but an index.\n",
    "\n",
    "In the case where our selected column is an index, we can use ```index``` to select the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_delays[origin_delays.index == 'SFO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9a-7yxHADB1D"
   },
   "source": [
    "## Resources\n",
    "- [Python Pandas Series](https://www.geeksforgeeks.org/python-pandas-series/)\n",
    "- [Pandas API Reference Merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n",
    "- [Join types](https://www.codespot.org/sql-join/)\n",
    "- [Flight Delay Prediction data](https://www.kaggle.com/divyansh22/flight-delay-prediction)\n",
    "- [Airline Delay Causes](https://www.kaggle.com/anshuls235/airline-delay-causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "1. Find out five largest airlines by the number of flights in January\n",
    "2. Calculate cancellation percentages of the top 5 airlines\n",
    "3. Find out the percentage of flights that managed to arrive within 15 minutes even though the flight departed more than 15 minutes past scheduled departure time (Hint: you may use ```DEP_DEL15 == 1``` and ```ARR_DEL15 == 0```)\n",
    "4. Convert categorical column (airline code / name) to numerical column and plot data visualizations for each airline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Advanced Data Wrangling with Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
